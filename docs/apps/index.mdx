---
title: All apps
description: Quick deploy apps on CUDO Compute.
---

<CardGroup cols={2}>
    <Card title="Dedicated LLM Inference" href="/docs/apps/dedicated-inference-vllm">Quick deploy popular LLMs on a dedicated GPU.</Card>
    <Card title="Dify" href="/docs/apps/dify">Build LLM Chatbots on CUDO Compute.</Card>
    <Card title="JupyterHub" href="/docs/apps/jupyterhub">Multi-user Jupyter Notebooks on CUDO Compute.</Card>
    <Card title="JupyterLab" href="/docs/apps/jupyterlab">Jupyter Notebooks on CUDO Compute.</Card>
    <Card title="Ollama" href="/docs/apps/ollama">Ollama is the easiest way to deploy open source LLMs</Card>
    <Card title="OpenManus" href="/docs/apps/openmanus">OpenManus AI agent on CUDO Compute.</Card>
    <Card title="vLLM" href="/docs/apps/vllm">vLLM is used to deploy open source LLMs for high performance</Card> 
</CardGroup>

## Need help?
<Note>
If you have a specific use case you'd like to see covered, please let us know! We're always looking to expand our apps based on user feedback. You can reach out to us via the support chat in the CUDO Compute web console or email us at support@cudocompute.com.
</Note>
